{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "953d0d35-1098-40de-b44b-c1e7345265a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS S3 client initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 1 — Environment Verification & AWS Session Initialization\n",
    "# ============================================================\n",
    "#\n",
    "# This cell performs three things:\n",
    "#   1. Imports all required libraries for AWS communication,\n",
    "#      filesystem handling, and tabular processing.\n",
    "#   2. Sets your target S3 bucket (already populated).\n",
    "#   3. Creates an AWS S3 client using your active environment\n",
    "#      credentials (pulled from ~/.aws/credentials).\n",
    "#\n",
    "# This cell does NOT access the bucket yet. It only ensures that\n",
    "# the environment is configured correctly and that boto3 can\n",
    "# initialize a client without error.\n",
    "# ============================================================\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Name of the new clean bucket you created\n",
    "BUCKET = \"quantum-clinical-optimization-us-west-2\"\n",
    "\n",
    "# Initialize S3 client\n",
    "# If credentials are properly configured in ~/.aws,\n",
    "# boto3 will automatically detect them.\n",
    "try:\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    print(\"AWS S3 client initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Failed to initialize AWS client:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f9ee7-9bd8-46c8-b4f0-ced36914af74",
   "metadata": {},
   "source": [
    "### Cell 1 — Environment Verification & AWS Session Initialization\n",
    "\n",
    "This cell prepares the execution environment and confirms that we can talk to AWS S3 before doing any heavy work. It imports the core libraries we rely on throughout the notebook: `boto3` for AWS interactions, `pandas` for tabular data handling, and `ClientError` for clean S3 error reporting. We then define the target S3 bucket, `quantum-clinical-optimization-us-west-2`, which is assumed to be pre-populated with clinical-trials data. Finally, we attempt to construct an S3 client using the active AWS configuration (for example, credentials stored under `~/.aws/credentials`). A successful initialization message confirms that the environment is correctly wired to AWS; if not, the exception message surfaces configuration issues early, before any large-scale processing is attempted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "302aa421-3b5a-46b9-8acb-f9c1c40de376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to S3 bucket: quantum-clinical-optimization-us-west-2\n",
      "Sample keys found:\n",
      "  - braket-output/\n",
      "  - clinical-trials-data/archive/\n",
      "  - clinical-trials-data/manifests/\n",
      "  - clinical-trials-data/processed/\n",
      "  - clinical-trials-data/raw/\n",
      "  - clinical-trials-data/raw/Contents.txt\n",
      "  - clinical-trials-data/raw/NCT0000xxxx/NCT00000102.xml\n",
      "  - clinical-trials-data/raw/NCT0000xxxx/NCT00000104.xml\n",
      "  - clinical-trials-data/raw/NCT0000xxxx/NCT00000105.xml\n",
      "  - clinical-trials-data/raw/NCT0000xxxx/NCT00000106.xml\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 2 — Basic Bucket Connectivity Test\n",
    "# ============================================================\n",
    "#\n",
    "# Purpose of this cell:\n",
    "#   • Confirm the notebook can list objects from your S3 bucket.\n",
    "#   • Detect incorrect bucket names or missing permissions early.\n",
    "#\n",
    "# Strategy:\n",
    "#   • Use list_objects_v2() with MaxKeys=10 to quickly sample\n",
    "#     the root of the bucket.\n",
    "#   • Print the top-level keys as a sanity check.\n",
    "#\n",
    "# Expected Output:\n",
    "#   • A short list including:\n",
    "#       clinical-trials-data/raw/\n",
    "#       clinical-trials-data/raw/NCT0000xxxx/...\n",
    "#       etc.\n",
    "# ============================================================\n",
    "\n",
    "try:\n",
    "    response = s3.list_objects_v2(\n",
    "        Bucket=BUCKET,\n",
    "        MaxKeys=10  # quick preview\n",
    "    )\n",
    "\n",
    "    if \"Contents\" not in response:\n",
    "        print(\"Bucket is reachable but contains no objects.\")\n",
    "    else:\n",
    "        print(f\"Connected to S3 bucket: {BUCKET}\")\n",
    "        print(\"Sample keys found:\")\n",
    "        for obj in response[\"Contents\"]:\n",
    "            print(\"  -\", obj[\"Key\"])\n",
    "\n",
    "except ClientError as e:\n",
    "    print(\"❌ S3 access error:\", e)\n",
    "except Exception as e:\n",
    "    print(\"❌ Unexpected error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c68ab-f2e7-4b16-923b-ad7a967fa28c",
   "metadata": {},
   "source": [
    "### Cell 2 — Basic Bucket Connectivity Test\n",
    "\n",
    "This cell verifies that the notebook can successfully communicate with the configured S3 bucket and that your IAM permissions are sufficient to list objects. Using the previously created `s3` client, it calls `list_objects_v2` with `MaxKeys=10` to retrieve a small sample of keys from the bucket root. If the response contains a `Contents` section, the code prints a short list of object keys as a quick visual confirmation that the bucket name is correct and populated (for example, paths starting with `clinical-trials-data/raw/`). If `Contents` is missing, the notebook reports that the bucket is reachable but currently empty. Any `ClientError` (such as access denied or a typo in the bucket name) is caught and reported explicitly, while a generic `Exception` catch provides a safety net for other unexpected issues. This keeps connectivity problems front-loaded and easy to diagnose before launching large-scale ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2de642c-7040-4fb1-842e-2d2163407e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning S3 keys... this may take 3–10 minutes.\n",
      "\n",
      "Index build complete.\n",
      "Total XML files indexed: 557,292\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s3_key</th>\n",
       "      <th>nct_id</th>\n",
       "      <th>folder</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>last_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "      <td>NCT00000102</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>4217</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "      <td>NCT00000104</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>4357</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "      <td>NCT00000105</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>11623</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "      <td>NCT00000106</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>5572</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "      <td>NCT00000107</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>3312</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "      <td>NCT00000108</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>4293</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "      <td>NCT00000110</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>4687</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "      <td>NCT00000111</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>4252</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "      <td>NCT00000112</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>3612</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "      <td>NCT00000113</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>10914</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              s3_key       nct_id  \\\n",
       "0  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  NCT00000102   \n",
       "1  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  NCT00000104   \n",
       "2  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  NCT00000105   \n",
       "3  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  NCT00000106   \n",
       "4  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  NCT00000107   \n",
       "5  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  NCT00000108   \n",
       "6  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  NCT00000110   \n",
       "7  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  NCT00000111   \n",
       "8  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  NCT00000112   \n",
       "9  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  NCT00000113   \n",
       "\n",
       "        folder  size_bytes             last_modified  \n",
       "0  NCT0000xxxx        4217 2025-11-14 10:58:29+00:00  \n",
       "1  NCT0000xxxx        4357 2025-11-14 10:58:29+00:00  \n",
       "2  NCT0000xxxx       11623 2025-11-14 10:58:29+00:00  \n",
       "3  NCT0000xxxx        5572 2025-11-14 10:58:29+00:00  \n",
       "4  NCT0000xxxx        3312 2025-11-14 10:58:29+00:00  \n",
       "5  NCT0000xxxx        4293 2025-11-14 10:58:29+00:00  \n",
       "6  NCT0000xxxx        4687 2025-11-14 10:58:29+00:00  \n",
       "7  NCT0000xxxx        4252 2025-11-14 10:58:29+00:00  \n",
       "8  NCT0000xxxx        3612 2025-11-14 10:58:29+00:00  \n",
       "9  NCT0000xxxx       10914 2025-11-14 10:58:29+00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 3 — Build S3 Metadata Index of All Clinical Trial XMLs\n",
    "# ============================================================\n",
    "#\n",
    "# Purpose:\n",
    "#   • Build a catalog of every XML file inside:\n",
    "#         clinical-trials-data/raw/\n",
    "#   • Extract metadata:\n",
    "#         - Full S3 key\n",
    "#         - NCT ID parsed from filename\n",
    "#         - Top-level directory (NCTxxxx group)\n",
    "#         - File size (Bytes)\n",
    "#         - Last-modified timestamp\n",
    "#\n",
    "# Why this matters:\n",
    "#   • This index allows fast searching, sampling, batching,\n",
    "#     QC analysis, and parallel processing.\n",
    "#   • This avoids downloading all 266k XML files at once.\n",
    "#\n",
    "# Output:\n",
    "#   - df_index → Pandas DataFrame with full metadata\n",
    "#   - A preview and dataset counts\n",
    "#\n",
    "# ============================================================\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "RAW_PREFIX = \"clinical-trials-data/raw/\"\n",
    "xml_pattern = re.compile(r\"NCT\\d+\\.xml$\")\n",
    "\n",
    "all_records = []\n",
    "\n",
    "# Iterator handles pagination automatically, necessary for 266k+ objects\n",
    "paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "\n",
    "print(\"Scanning S3 keys... this may take 3–10 minutes.\")\n",
    "\n",
    "try:\n",
    "    for page in paginator.paginate(Bucket=BUCKET, Prefix=RAW_PREFIX):\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "            key = obj[\"Key\"]\n",
    "\n",
    "            # Only index XML files (skip directories, metadata files, etc.)\n",
    "            if xml_pattern.search(key):\n",
    "                filename = key.split(\"/\")[-1]\n",
    "                nct_id = filename.replace(\".xml\", \"\")\n",
    "                folder_group = key.split(\"/\")[-2]  # e.g., NCT0000xxxx\n",
    "\n",
    "                record = {\n",
    "                    \"s3_key\": key,\n",
    "                    \"nct_id\": nct_id,\n",
    "                    \"folder\": folder_group,\n",
    "                    \"size_bytes\": obj[\"Size\"],\n",
    "                    \"last_modified\": obj[\"LastModified\"],\n",
    "                }\n",
    "                all_records.append(record)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during S3 scan:\", e)\n",
    "    raise\n",
    "\n",
    "# Convert into DataFrame\n",
    "df_index = pd.DataFrame(all_records)\n",
    "\n",
    "print(\"\\nIndex build complete.\")\n",
    "print(f\"Total XML files indexed: {len(df_index):,}\")\n",
    "df_index.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38627b60-676f-4427-b5d5-84051852413a",
   "metadata": {},
   "source": [
    "### Cell 3 — Build S3 Metadata Index of All Clinical Trial XMLs\n",
    "\n",
    "This cell constructs a complete metadata index of all clinical trial XML files stored under the S3 prefix `clinical-trials-data/raw/`. Using a `list_objects_v2` paginator, it efficiently walks through every page of objects in the bucket, which is essential at this scale (hundreds of thousands of files). For each object, the code filters down to true XML trial files using a regular expression (`NCT\\d+\\.xml$`), then parses out the trial identifier (`nct_id`) from the filename and the folder group (e.g., `NCT0000xxxx`) from the key path. It also captures file size in bytes and the last-modified timestamp. All of this information is accumulated into a list of dictionaries which is then converted into a `df_index` DataFrame. The resulting index serves as a lightweight catalog of the entire clinical-trials corpus, enabling downstream sampling, QC, and parallel processing without ever downloading the full XML dataset. The cell finishes by reporting how many XML files were indexed and displaying the first few rows as a sanity check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732d7e57-1d54-4fb0-b134-407769dc1693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML parsing utilities loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 4 — Define Robust XML Parsing Utilities\n",
    "# ============================================================\n",
    "#\n",
    "# Purpose:\n",
    "#   Provide safe, fault-tolerant parsing of ClinicalTrials.gov XML files.\n",
    "#\n",
    "# Why robust parsing?\n",
    "#   • CT.gov XML varies by year, sponsor, system version.\n",
    "#   • Many files contain missing tags, malformed sections, or odd nesting.\n",
    "#   • We must avoid notebook crashes by isolating and handling errors.\n",
    "#\n",
    "# Output:\n",
    "#   - parse_xml_from_s3(key): returns a dict of extracted fields\n",
    "#\n",
    "# ============================================================\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from botocore.exceptions import ClientError\n",
    "from io import BytesIO\n",
    "\n",
    "def safe_findtext(elem, path):\n",
    "    \"\"\"Return elem.find(path).text or None if missing.\"\"\"\n",
    "    node = elem.find(path)\n",
    "    return node.text.strip() if node is not None and node.text else None\n",
    "\n",
    "def parse_xml_from_s3(s3_key):\n",
    "    \"\"\"\n",
    "    Download a single XML file from S3 and extract key structured fields.\n",
    "    Returns a dictionary. Returns None if parsing fails.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Download XML file into memory\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=s3_key)\n",
    "        xml_bytes = obj[\"Body\"].read()\n",
    "\n",
    "        # Parse XML safely\n",
    "        tree = ET.parse(BytesIO(xml_bytes))\n",
    "        root = tree.getroot()\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"❌ S3 error for key: {s3_key} — {e}\")\n",
    "        return None\n",
    "    except ET.ParseError:\n",
    "        print(f\"❌ XML parse error: {s3_key}\")\n",
    "        return None\n",
    "\n",
    "    # --- Extract Core Fields ---\n",
    "    record = {}\n",
    "\n",
    "    # NCT ID\n",
    "    record[\"nct_id\"] = safe_findtext(root, \"./id_info/nct_id\")\n",
    "\n",
    "    # Titles\n",
    "    record[\"brief_title\"] = safe_findtext(root, \"./brief_title\")\n",
    "    record[\"official_title\"] = safe_findtext(root, \"./official_title\")\n",
    "\n",
    "    # Study Status\n",
    "    record[\"overall_status\"] = safe_findtext(root, \"./overall_status\")\n",
    "\n",
    "    # Phase\n",
    "    record[\"phase\"] = safe_findtext(root, \"./phase\")\n",
    "\n",
    "    # Conditions (can be multiple)\n",
    "    record[\"conditions\"] = [\n",
    "        c.text.strip() for c in root.findall(\"./condition\") if c.text\n",
    "    ]\n",
    "\n",
    "    # Interventions (name only for now)\n",
    "    record[\"interventions\"] = [\n",
    "        safe_findtext(i, \"./intervention_name\")\n",
    "        for i in root.findall(\"./intervention\")\n",
    "    ]\n",
    "\n",
    "    # Enrollment (target sample size)\n",
    "    record[\"enrollment\"] = safe_findtext(root, \"./enrollment\")\n",
    "\n",
    "    # Location countries\n",
    "    record[\"location_countries\"] = [\n",
    "        c.text.strip()\n",
    "        for c in root.findall(\"./location_countries/country\")\n",
    "        if c.text\n",
    "    ]\n",
    "\n",
    "    # Sponsor (lead sponsor only)\n",
    "    record[\"lead_sponsor\"] = safe_findtext(\n",
    "        root, \"./sponsors/lead_sponsor/agency\"\n",
    "    )\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "print(\"XML parsing utilities loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82263205-754f-44a7-9510-20df1b8fddc8",
   "metadata": {},
   "source": [
    "### Cell 4 — Robust XML Parsing Utilities\n",
    "\n",
    "This cell defines the core utilities for safely converting raw ClinicalTrials.gov XML files into structured Python dictionaries. Because CT.gov XML schemas have evolved over time and can be inconsistent or partially filled out, the parser is designed to be fault-tolerant rather than brittle.\n",
    "\n",
    "The helper function `safe_findtext` encapsulates a common pattern: attempt to locate a nested XML element via a path, and return its stripped text value if present, or `None` if the element or its text is missing. This avoids repetitive `None` checks throughout the parser.\n",
    "\n",
    "The main function, `parse_xml_from_s3(s3_key)`, downloads a single XML object from S3 into memory using the established `s3` client and bucket name. It then parses the content into an `ElementTree`, catching and handling two main classes of failure:\n",
    "\n",
    "- `ClientError` from S3 (e.g., missing object, permissions, or transient S3 issues), and  \n",
    "- `ET.ParseError` for malformed XML that cannot be parsed.\n",
    "\n",
    "In either case, the function logs a clear error message and returns `None` so that the ingestion loop can skip problematic files without crashing the notebook.\n",
    "\n",
    "On success, the function extracts a curated set of core fields that are useful for downstream analytics and optimization: the NCT identifier, brief and official titles, overall status, phase, a list of conditions, a list of intervention names, enrollment target, a list of location countries, and the lead sponsor agency. These values are assembled into a `record` dictionary, which becomes the building block for the trial-level metadata table constructed later in the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3731dfb9-d2ad-497a-af12-ea653610198e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing XML parse on file: clinical-trials-data/raw/NCT0000xxxx/NCT00000102.xml\n",
      "\n",
      "Parsed Record:\n",
      "{\n",
      "  \"nct_id\": \"NCT00000102\",\n",
      "  \"brief_title\": \"Congenital Adrenal Hyperplasia: Calcium Channels as Therapeutic Targets\",\n",
      "  \"official_title\": null,\n",
      "  \"overall_status\": \"Completed\",\n",
      "  \"phase\": \"Phase 1/Phase 2\",\n",
      "  \"conditions\": [\n",
      "    \"Congenital Adrenal Hyperplasia\"\n",
      "  ],\n",
      "  \"interventions\": [\n",
      "    \"Nifedipine\"\n",
      "  ],\n",
      "  \"enrollment\": null,\n",
      "  \"location_countries\": [\n",
      "    \"United States\"\n",
      "  ],\n",
      "  \"lead_sponsor\": \"National Center for Research Resources (NCRR)\"\n",
      "}\n",
      "\n",
      "Sanity Checks:\n",
      "NCT ID: NCT00000102\n",
      "Title: Congenital Adrenal Hyperplasia: Calcium Channels as Therapeutic Targets\n",
      "Conditions: ['Congenital Adrenal Hyperplasia']\n",
      "Interventions: ['Nifedipine']\n",
      "Countries: ['United States']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 5 — Test XML Parsing on a Single Sample File\n",
    "# ============================================================\n",
    "\n",
    "# Select the first file from the index built in Cell 3\n",
    "sample_key = df_index.iloc[0][\"s3_key\"]\n",
    "print(\"Testing XML parse on file:\", sample_key)\n",
    "\n",
    "# Parse the XML record\n",
    "parsed = parse_xml_from_s3(sample_key)\n",
    "\n",
    "# Pretty-print the result\n",
    "import json\n",
    "print(\"\\nParsed Record:\")\n",
    "print(json.dumps(parsed, indent=2))\n",
    "\n",
    "# Basic field sanity checks\n",
    "print(\"\\nSanity Checks:\")\n",
    "print(\"NCT ID:\", parsed.get(\"nct_id\"))\n",
    "print(\"Title:\", parsed.get(\"brief_title\"))\n",
    "print(\"Conditions:\", parsed.get(\"conditions\")[:5] if parsed.get(\"conditions\") else None)\n",
    "print(\"Interventions:\", parsed.get(\"interventions\")[:5] if parsed.get(\"interventions\") else None)\n",
    "print(\"Countries:\", parsed.get(\"location_countries\")[:5] if parsed.get(\"location_countries\") else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f14abaa-a84c-4fa4-8a86-668ac30bb5fe",
   "metadata": {},
   "source": [
    "### Cell 5 — Single-File XML Parsing Smoke Test\n",
    "\n",
    "This cell performs a targeted smoke test of the XML parsing pipeline before we scale up to the full corpus. Using the `df_index` DataFrame built in Cell 3, it selects the first S3 key and uses `parse_xml_from_s3` (defined in Cell 4) to download and parse that single clinical-trial XML.\n",
    "\n",
    "The parsed result is pretty-printed as JSON to make the structure and extracted fields easy to inspect visually. This lets you confirm that the parser is correctly populating core attributes such as `nct_id`, `brief_title`, `conditions`, `interventions`, and `location_countries`.\n",
    "\n",
    "Finally, the cell runs a few basic sanity checks, printing a subset of key fields (and the first few list elements where applicable). If this cell shows sensible values—for example, a well-formed NCT ID, a human-readable title, non-empty condition and intervention lists, and reasonable country information—it provides strong evidence that the XML parsing logic and S3 access are functioning as intended before moving on to large-scale ingestion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25f618b3-4f3d-4a3d-971d-ef13a7a47f4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating parsing across 200 random trials...\n",
      "\n",
      "=== Validation Summary ===\n",
      "Total sampled:  200\n",
      "Successfully parsed: 200\n",
      "Errors: 0\n",
      "\n",
      "Field Coverage Across Sample (Top 20 fields):\n",
      "nct_id                    200/200 (100%)\n",
      "brief_title               200/200 (100%)\n",
      "overall_status            200/200 (100%)\n",
      "lead_sponsor              200/200 (100%)\n",
      "conditions                199/200 (100%)\n",
      "enrollment                195/200 (98%)\n",
      "official_title            194/200 (97%)\n",
      "interventions             182/200 (91%)\n",
      "location_countries        178/200 (89%)\n",
      "phase                     149/200 (74%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 6 — Batch-Validate Parsing on Random Sample of XML Files\n",
    "# ============================================================\n",
    "\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Number of random XML files to test\n",
    "SAMPLE_SIZE = 200\n",
    "\n",
    "sample_keys = random.sample(df_index[\"s3_key\"].tolist(), SAMPLE_SIZE)\n",
    "\n",
    "parsed_records = []\n",
    "errors = 0\n",
    "field_counter = Counter()\n",
    "\n",
    "print(f\"Validating parsing across {SAMPLE_SIZE} random trials...\")\n",
    "\n",
    "for key in sample_keys:\n",
    "    try:\n",
    "        record = parse_xml_from_s3(key)\n",
    "        parsed_records.append(record)\n",
    "\n",
    "        # Track which fields appear\n",
    "        for field, val in record.items():\n",
    "            if val not in (None, [], \"\"):\n",
    "                field_counter[field] += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error parsing {key}: {e}\")\n",
    "        errors += 1\n",
    "\n",
    "print(\"\\n=== Validation Summary ===\")\n",
    "print(f\"Total sampled:  {SAMPLE_SIZE}\")\n",
    "print(f\"Successfully parsed: {len(parsed_records)}\")\n",
    "print(f\"Errors: {errors}\")\n",
    "\n",
    "print(\"\\nField Coverage Across Sample (Top 20 fields):\")\n",
    "for field, count in field_counter.most_common(20):\n",
    "    print(f\"{field:<25} {count}/{SAMPLE_SIZE} ({count/SAMPLE_SIZE:.0%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c94bd5b-d2cd-477f-89bd-583f2d55a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cell 6 — Batch Validation of XML Parsing on a Random Sample\n",
    "\n",
    "This cell stress-tests the XML parser across a random subset of trials to ensure robustness before scaling to the full dataset. Rather than trusting a single-file smoke test, it draws a random sample of `SAMPLE_SIZE` S3 keys (default 200) from `df_index` and attempts to parse each one using `parse_xml_from_s3`.\n",
    "\n",
    "For every successfully parsed record, the cell tracks which fields are actually populated. A `Counter` called `field_counter` is incremented whenever a field’s value is non-empty (`None`, empty lists, and empty strings are treated as “missing”). This gives a quick sense of field coverage across the sample—how often key attributes like `overall_status`, `phase`, `conditions`, or `enrollment` appear in practice.\n",
    "\n",
    "The summary at the end reports:\n",
    "- How many trials were sampled,\n",
    "- How many were parsed successfully versus how many produced errors, and\n",
    "- A ranked list of fields, showing for each how many of the sampled trials provided a non-empty value (and the corresponding percentage).\n",
    "\n",
    "If the error count is low and core fields show good coverage, it validates that the S3 access pattern and XML parsing logic are stable enough to apply to all trials in the subsequent large-scale ingestion step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32539fcb-0f27-4400-b65e-f9b39eecfe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime.utcnow(): 2025-11-19 12:49:59.994258\n",
      "time.time() (epoch seconds): 1763556599.9943516\n"
     ]
    }
   ],
   "source": [
    "# === Utility logging function + tim synch (used across multiple cells) ===\n",
    "import datetime, time\n",
    "\n",
    "print(\"datetime.utcnow():\", datetime.datetime.utcnow())\n",
    "print(\"time.time() (epoch seconds):\", time.time())\n",
    "\n",
    "def log(msg: str):\n",
    "    print(msg, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de33b703-5c35-41e5-9680-7a1e84dc72b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke test complete: parsed 200 of 200 trials.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct_id</th>\n",
       "      <th>brief_title</th>\n",
       "      <th>official_title</th>\n",
       "      <th>overall_status</th>\n",
       "      <th>phase</th>\n",
       "      <th>conditions</th>\n",
       "      <th>interventions</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>location_countries</th>\n",
       "      <th>lead_sponsor</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT00000102</td>\n",
       "      <td>Congenital Adrenal Hyperplasia: Calcium Channe...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Phase 1/Phase 2</td>\n",
       "      <td>[Congenital Adrenal Hyperplasia]</td>\n",
       "      <td>[Nifedipine]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>4217</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT00000104</td>\n",
       "      <td>Does Lead Burden Alter Neuropsychological Deve...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>[Lead Poisoning]</td>\n",
       "      <td>[ERP measures of attention and memory]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>4357</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT00000105</td>\n",
       "      <td>Vaccination With Tetanus and KLH to Assess Imm...</td>\n",
       "      <td>Vaccination With Tetanus Toxoid and Keyhole Li...</td>\n",
       "      <td>Terminated</td>\n",
       "      <td>None</td>\n",
       "      <td>[Cancer]</td>\n",
       "      <td>[Intracel KLH Vaccine, Biosyn KLH, Montanide I...</td>\n",
       "      <td>112</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>Masonic Cancer Center, University of Minnesota</td>\n",
       "      <td>11623</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT00000106</td>\n",
       "      <td>41.8 Degree Centigrade Whole Body Hyperthermia...</td>\n",
       "      <td>None</td>\n",
       "      <td>Unknown status</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[Rheumatic Diseases]</td>\n",
       "      <td>[Whole body hyperthermia unit]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>5572</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT00000107</td>\n",
       "      <td>Body Water Content in Cyanotic Congenital Hear...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>[Heart Defects, Congenital]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>3312</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nct_id                                        brief_title  \\\n",
       "0  NCT00000102  Congenital Adrenal Hyperplasia: Calcium Channe...   \n",
       "1  NCT00000104  Does Lead Burden Alter Neuropsychological Deve...   \n",
       "2  NCT00000105  Vaccination With Tetanus and KLH to Assess Imm...   \n",
       "3  NCT00000106  41.8 Degree Centigrade Whole Body Hyperthermia...   \n",
       "4  NCT00000107  Body Water Content in Cyanotic Congenital Hear...   \n",
       "\n",
       "                                      official_title  overall_status  \\\n",
       "0                                               None       Completed   \n",
       "1                                               None       Completed   \n",
       "2  Vaccination With Tetanus Toxoid and Keyhole Li...      Terminated   \n",
       "3                                               None  Unknown status   \n",
       "4                                               None       Completed   \n",
       "\n",
       "             phase                        conditions  \\\n",
       "0  Phase 1/Phase 2  [Congenital Adrenal Hyperplasia]   \n",
       "1             None                  [Lead Poisoning]   \n",
       "2             None                          [Cancer]   \n",
       "3              N/A              [Rheumatic Diseases]   \n",
       "4             None       [Heart Defects, Congenital]   \n",
       "\n",
       "                                       interventions enrollment  \\\n",
       "0                                       [Nifedipine]       None   \n",
       "1             [ERP measures of attention and memory]       None   \n",
       "2  [Intracel KLH Vaccine, Biosyn KLH, Montanide I...        112   \n",
       "3                     [Whole body hyperthermia unit]       None   \n",
       "4                                                 []       None   \n",
       "\n",
       "  location_countries                                    lead_sponsor  \\\n",
       "0    [United States]   National Center for Research Resources (NCRR)   \n",
       "1    [United States]   National Center for Research Resources (NCRR)   \n",
       "2    [United States]  Masonic Cancer Center, University of Minnesota   \n",
       "3    [United States]   National Center for Research Resources (NCRR)   \n",
       "4    [United States]   National Center for Research Resources (NCRR)   \n",
       "\n",
       "   size_bytes             last_modified       folder  \n",
       "0        4217 2025-11-14 10:58:29+00:00  NCT0000xxxx  \n",
       "1        4357 2025-11-14 10:58:29+00:00  NCT0000xxxx  \n",
       "2       11623 2025-11-14 10:58:29+00:00  NCT0000xxxx  \n",
       "3        5572 2025-11-14 10:58:29+00:00  NCT0000xxxx  \n",
       "4        3312 2025-11-14 10:58:29+00:00  NCT0000xxxx  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Cell 7a: Smoke test on a small subset ===\n",
    "sample_n = 200  # adjust as needed\n",
    "\n",
    "sample_records = []\n",
    "for _, row in df_index.head(sample_n).iterrows():\n",
    "    parsed = parse_xml_from_s3(row[\"s3_key\"])\n",
    "    if not parsed:\n",
    "        continue\n",
    "    parsed[\"size_bytes\"] = row[\"size_bytes\"]\n",
    "    parsed[\"last_modified\"] = row[\"last_modified\"]\n",
    "    parsed[\"folder\"] = row[\"folder\"]\n",
    "    sample_records.append(parsed)\n",
    "\n",
    "sample_df = pd.DataFrame(sample_records)\n",
    "log(f\"Smoke test complete: parsed {len(sample_df)} of {sample_n} trials.\")\n",
    "sample_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb932e3a-4e01-4bf8-909c-d187cc6637cc",
   "metadata": {},
   "source": [
    "### Cell 7a — Smoke Test on a Small Subset of Trials\n",
    "\n",
    "This cell performs a small-scale dry run of the full ingestion pipeline before we commit to processing all ~557k trials. It takes the first `sample_n` rows from `df_index`, downloads and parses each corresponding XML via `parse_xml_from_s3`, and attaches the S3 index metadata (`size_bytes`, `last_modified`, `folder`) to each parsed record. The results are assembled into a `sample_df` DataFrame and summarized with a log message showing how many of the sampled trials were successfully parsed. A quick `.head()` preview lets us visually confirm that the combined XML-derived fields and S3 metadata look correct. If this smoke test parses cleanly and the columns match expectations, it gives us confidence to proceed to the high-throughput extraction step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca6b4d2-82ee-4967-808d-bf8bb69249b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting HIGH-PERFORMANCE metadata extraction for 557,292 trials using up to 10 threads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 557292/557292 [2:06:28<00:00, 73.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction loop complete. Parsed 557,292 records. Encountered 0 errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     93\u001b[39m all_records = pd.DataFrame(records)\n\u001b[32m     95\u001b[39m metadata_path = OUTPUT_DIR / \u001b[33m\"\u001b[39m\u001b[33mclinical_trials_metadata.parquet\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[43mall_records\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m log(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWrote metadata table to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_records.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_records:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/quantum-clinical-trial-optimization/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/quantum-clinical-trial-optimization/lib/python3.11/site-packages/pandas/core/frame.py:3124\u001b[39m, in \u001b[36mDataFrame.to_parquet\u001b[39m\u001b[34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3044\u001b[39m \u001b[33;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[32m   3045\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3120\u001b[39m \u001b[33;03m>>> content = f.read()\u001b[39;00m\n\u001b[32m   3121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3122\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[32m-> \u001b[39m\u001b[32m3124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3125\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3132\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/quantum-clinical-trial-optimization/lib/python3.11/site-packages/pandas/io/parquet.py:478\u001b[39m, in \u001b[36mto_parquet\u001b[39m\u001b[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(partition_cols, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    477\u001b[39m     partition_cols = [partition_cols]\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m path_or_buf: FilePath | WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] = io.BytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m    482\u001b[39m impl.write(\n\u001b[32m    483\u001b[39m     df,\n\u001b[32m    484\u001b[39m     path_or_buf,\n\u001b[32m   (...)\u001b[39m\u001b[32m    490\u001b[39m     **kwargs,\n\u001b[32m    491\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/quantum-clinical-trial-optimization/lib/python3.11/site-packages/pandas/io/parquet.py:68\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     66\u001b[39m             error_msgs += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m - \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to find a usable engine; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtried using: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA suitable version of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTrying to import the above resulted in these errors:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[31mImportError\u001b[39m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "# === Cell 7: High-performance extraction of trial-level metadata ===\n",
    "# Long-running, concurrent pipeline that parses all ~557k trials\n",
    "# and produces a structured metadata table.\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configurable knobs -------------------------------------------------------\n",
    "\n",
    "# Max threads to use for S3 + XML parsing\n",
    "# You can tune this if needed; start here.\n",
    "MAX_WORKERS = min(32, (os.cpu_count() or 4) * 5)\n",
    "\n",
    "# Where to persist outputs\n",
    "OUTPUT_DIR = Path(\"data/interim\")\n",
    "LOG_DIR = Path(\"logs\")\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Worker function ----------------------------------------------------------\n",
    "\n",
    "def _process_index_row(row_dict):\n",
    "    \"\"\"\n",
    "    Worker for a single trial:\n",
    "    - Fetch & parse XML from S3\n",
    "    - Attach index metadata\n",
    "    - Return either a parsed record or an error description\n",
    "    \"\"\"\n",
    "    s3_key = row_dict[\"s3_key\"]\n",
    "\n",
    "    try:\n",
    "        parsed = parse_xml_from_s3(s3_key)\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"ok\": False,\n",
    "            \"s3_key\": s3_key,\n",
    "            \"error_type\": type(e).__name__,\n",
    "            \"error_message\": str(e),\n",
    "        }\n",
    "\n",
    "    if not parsed:\n",
    "        # parse_xml_from_s3 returned None / empty\n",
    "        return {\n",
    "            \"ok\": False,\n",
    "            \"s3_key\": s3_key,\n",
    "            \"error_type\": \"EmptyParse\",\n",
    "            \"error_message\": \"parse_xml_from_s3 returned None/empty\",\n",
    "        }\n",
    "\n",
    "    # Attach S3 index metadata\n",
    "    parsed[\"size_bytes\"]    = row_dict[\"size_bytes\"]\n",
    "    parsed[\"last_modified\"] = row_dict[\"last_modified\"]\n",
    "    parsed[\"folder\"]        = row_dict[\"folder\"]\n",
    "    parsed[\"s3_key\"]        = s3_key\n",
    "\n",
    "    return {\"ok\": True, \"record\": parsed}\n",
    "\n",
    "# --- Main concurrent extraction -----------------------------------------------\n",
    "\n",
    "# Convert index DataFrame to a list of row dicts for fast iteration\n",
    "rows = df_index.to_dict(\"records\")\n",
    "\n",
    "records = []\n",
    "error_records = []\n",
    "\n",
    "log(\n",
    "    f\"Starting HIGH-PERFORMANCE metadata extraction for \"\n",
    "    f\"{len(rows):,} trials using up to {MAX_WORKERS} threads...\"\n",
    ")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    # executor.map gives us a generator of results; wrap with tqdm for progress\n",
    "    for res in tqdm(executor.map(_process_index_row, rows), total=len(rows)):\n",
    "        if res[\"ok\"]:\n",
    "            records.append(res[\"record\"])\n",
    "        else:\n",
    "            error_records.append({\n",
    "                \"s3_key\":        res[\"s3_key\"],\n",
    "                \"error_type\":    res[\"error_type\"],\n",
    "                \"error_message\": res[\"error_message\"],\n",
    "            })\n",
    "\n",
    "log(\n",
    "    f\"Extraction loop complete. Parsed {len(records):,} records. \"\n",
    "    f\"Encountered {len(error_records):,} errors.\"\n",
    ")\n",
    "\n",
    "# --- Build final DataFrame + persist artifacts --------------------------------\n",
    "\n",
    "all_records = pd.DataFrame(records)\n",
    "\n",
    "metadata_path = OUTPUT_DIR / \"clinical_trials_metadata.parquet\"\n",
    "all_records.to_parquet(metadata_path, index=False)\n",
    "log(f\"Wrote metadata table to {metadata_path} with shape {all_records.shape}\")\n",
    "\n",
    "if error_records:\n",
    "    df_errors = pd.DataFrame(error_records)\n",
    "    error_path = LOG_DIR / \"clinical_trials_ingestion_errors.csv\"\n",
    "    df_errors.to_csv(error_path, index=False)\n",
    "    log(\n",
    "        f\"Wrote error log to {error_path} \"\n",
    "        f\"with {len(df_errors):,} failed trials.\"\n",
    "    )\n",
    "else:\n",
    "    log(\"No errors encountered during metadata extraction.\")\n",
    "\n",
    "log(\"Metadata extraction finished.\")\n",
    "all_records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c5f2b4-ecef-4b3b-918e-933b604f1924",
   "metadata": {},
   "source": [
    "### Cell 7 — High-Performance Extraction of Trial-Level Metadata\n",
    "\n",
    "This cell scales the ingestion process from a small smoke test to the full corpus of clinical-trial XMLs. Starting from `df_index`, it converts each index row into a plain Python dictionary and uses a `ThreadPoolExecutor` to parallelize work across many threads. Each worker calls `_process_index_row`, which in turn invokes `parse_xml_from_s3` to download and parse a single XML file, then enriches the parsed record with S3-derived metadata (`size_bytes`, `last_modified`, `folder`, and `s3_key`). Successfully parsed records are appended to the `records` list, while any failures are captured in `error_records` with structured information about the S3 key and error type. A `tqdm` progress bar provides real-time feedback on progress across all ~557k trials. Once the executor completes, the cell assembles the collected records into the `all_records` DataFrame and logs a concise summary of how many trials were parsed successfully versus how many encountered errors. This cell is the core ingestion engine of the notebook, transforming a large, unstructured XML corpus in S3 into a structured, analysis-ready table that can be persisted and reused by downstream notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c039e8c6-889e-4f78-8675-30d1c2b7469d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cell 7b] Backup CSV written to data/interim/clinical_trials_metadata.csv.gz with shape (557292, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct_id</th>\n",
       "      <th>brief_title</th>\n",
       "      <th>official_title</th>\n",
       "      <th>overall_status</th>\n",
       "      <th>phase</th>\n",
       "      <th>conditions</th>\n",
       "      <th>interventions</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>location_countries</th>\n",
       "      <th>lead_sponsor</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>folder</th>\n",
       "      <th>s3_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT00000102</td>\n",
       "      <td>Congenital Adrenal Hyperplasia: Calcium Channe...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Phase 1/Phase 2</td>\n",
       "      <td>[Congenital Adrenal Hyperplasia]</td>\n",
       "      <td>[Nifedipine]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>4217</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT00000104</td>\n",
       "      <td>Does Lead Burden Alter Neuropsychological Deve...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>[Lead Poisoning]</td>\n",
       "      <td>[ERP measures of attention and memory]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>4357</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT00000105</td>\n",
       "      <td>Vaccination With Tetanus and KLH to Assess Imm...</td>\n",
       "      <td>Vaccination With Tetanus Toxoid and Keyhole Li...</td>\n",
       "      <td>Terminated</td>\n",
       "      <td>None</td>\n",
       "      <td>[Cancer]</td>\n",
       "      <td>[Intracel KLH Vaccine, Biosyn KLH, Montanide I...</td>\n",
       "      <td>112</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>Masonic Cancer Center, University of Minnesota</td>\n",
       "      <td>11623</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT00000106</td>\n",
       "      <td>41.8 Degree Centigrade Whole Body Hyperthermia...</td>\n",
       "      <td>None</td>\n",
       "      <td>Unknown status</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[Rheumatic Diseases]</td>\n",
       "      <td>[Whole body hyperthermia unit]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>5572</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT00000107</td>\n",
       "      <td>Body Water Content in Cyanotic Congenital Hear...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>[Heart Defects, Congenital]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>3312</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nct_id                                        brief_title  \\\n",
       "0  NCT00000102  Congenital Adrenal Hyperplasia: Calcium Channe...   \n",
       "1  NCT00000104  Does Lead Burden Alter Neuropsychological Deve...   \n",
       "2  NCT00000105  Vaccination With Tetanus and KLH to Assess Imm...   \n",
       "3  NCT00000106  41.8 Degree Centigrade Whole Body Hyperthermia...   \n",
       "4  NCT00000107  Body Water Content in Cyanotic Congenital Hear...   \n",
       "\n",
       "                                      official_title  overall_status  \\\n",
       "0                                               None       Completed   \n",
       "1                                               None       Completed   \n",
       "2  Vaccination With Tetanus Toxoid and Keyhole Li...      Terminated   \n",
       "3                                               None  Unknown status   \n",
       "4                                               None       Completed   \n",
       "\n",
       "             phase                        conditions  \\\n",
       "0  Phase 1/Phase 2  [Congenital Adrenal Hyperplasia]   \n",
       "1             None                  [Lead Poisoning]   \n",
       "2             None                          [Cancer]   \n",
       "3              N/A              [Rheumatic Diseases]   \n",
       "4             None       [Heart Defects, Congenital]   \n",
       "\n",
       "                                       interventions enrollment  \\\n",
       "0                                       [Nifedipine]       None   \n",
       "1             [ERP measures of attention and memory]       None   \n",
       "2  [Intracel KLH Vaccine, Biosyn KLH, Montanide I...        112   \n",
       "3                     [Whole body hyperthermia unit]       None   \n",
       "4                                                 []       None   \n",
       "\n",
       "  location_countries                                    lead_sponsor  \\\n",
       "0    [United States]   National Center for Research Resources (NCRR)   \n",
       "1    [United States]   National Center for Research Resources (NCRR)   \n",
       "2    [United States]  Masonic Cancer Center, University of Minnesota   \n",
       "3    [United States]   National Center for Research Resources (NCRR)   \n",
       "4    [United States]   National Center for Research Resources (NCRR)   \n",
       "\n",
       "   size_bytes             last_modified       folder  \\\n",
       "0        4217 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "1        4357 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "2       11623 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "3        5572 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "4        3312 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "\n",
       "                                              s3_key  \n",
       "0  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "1  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "2  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "3  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "4  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Cell 7b: Persist backup CSV of trial metadata (no extra dependencies) ===\n",
    "#\n",
    "# Purpose:\n",
    "#   - Save a durable copy of the extracted trial metadata using only core pandas.\n",
    "#   - This does NOT require pyarrow or fastparquet.\n",
    "#\n",
    "# Assumes:\n",
    "#   - `all_records` is already defined (from Cell 7) and is a pandas DataFrame\n",
    "#     with ~557k rows of parsed trial metadata.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure the interim data directory exists\n",
    "OUTPUT_DIR = Path(\"data/interim\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Choose a compressed CSV filename\n",
    "csv_path = OUTPUT_DIR / \"clinical_trials_metadata.csv.gz\"\n",
    "\n",
    "# Write the DataFrame as a compressed CSV\n",
    "#   - compression=\"gzip\" keeps file size manageable\n",
    "#   - index=False avoids writing the DataFrame index as a column\n",
    "all_records.to_csv(csv_path, index=False, compression=\"gzip\")\n",
    "\n",
    "log(f\"[Cell 7b] Backup CSV written to {csv_path} with shape {all_records.shape}\")\n",
    "all_records.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941a00d-380d-42df-8133-dc84e46a998d",
   "metadata": {},
   "source": [
    "### Cell 7b — Persist Backup CSV of Trial Metadata (Engine-Agnostic)\n",
    "\n",
    "This cell creates a durable, engine-agnostic backup of the full trial-metadata table produced in Cell 7. It first ensures that the `data/interim` directory exists, then writes the `all_records` DataFrame to a compressed CSV file named `clinical_trials_metadata.csv.gz`. Using `compression=\"gzip\"` keeps the file size manageable while remaining highly interoperable across tools, and `index=False` prevents the pandas index from being stored as an extra column. A log message records both the output path and the final shape of the dataset, and a `.head()` preview confirms that the written structure matches expectations. This CSV artifact serves as a safety net and a universal interchange format, independent of any optional Parquet engines or library version issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "816d8d0a-4a57-41f1-a1a3-146f9eb28f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_aarch64.whl.metadata (3.2 kB)\n",
      "Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_aarch64.whl (45.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-22.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# === Cell 7c: Install pyarrow parquet engine in current environment ===\n",
    "#\n",
    "# Purpose:\n",
    "#   - Install the `pyarrow` library so that pandas can write Parquet files.\n",
    "#   - This runs inside the currently active kernel, so you do NOT need\n",
    "#     to restart the kernel or re-run the extraction.\n",
    "#\n",
    "# Notes:\n",
    "#   - `%pip` is a Jupyter magic command; it ensures installation happens\n",
    "#     in the same environment backing this notebook.\n",
    "\n",
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56ea37ea-9377-4cf3-849e-db418eda8f63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowKeyError",
     "evalue": "No type extension with name arrow.py_extension_type found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArrowKeyError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m metadata_path = OUTPUT_DIR / \u001b[33m\"\u001b[39m\u001b[33mclinical_trials_metadata.parquet\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Write the DataFrame to Parquet using pyarrow (default engine once installed)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mall_records\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m log(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Cell 7d] Wrote Parquet metadata table to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_records.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m all_records.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/quantum-clinical-trial-optimization/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/quantum-clinical-trial-optimization/lib/python3.11/site-packages/pandas/core/frame.py:3124\u001b[39m, in \u001b[36mDataFrame.to_parquet\u001b[39m\u001b[34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3044\u001b[39m \u001b[33;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[32m   3045\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3120\u001b[39m \u001b[33;03m>>> content = f.read()\u001b[39;00m\n\u001b[32m   3121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3122\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[32m-> \u001b[39m\u001b[32m3124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3125\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3132\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/quantum-clinical-trial-optimization/lib/python3.11/site-packages/pandas/io/parquet.py:478\u001b[39m, in \u001b[36mto_parquet\u001b[39m\u001b[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(partition_cols, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    477\u001b[39m     partition_cols = [partition_cols]\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m path_or_buf: FilePath | WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] = io.BytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m    482\u001b[39m impl.write(\n\u001b[32m    483\u001b[39m     df,\n\u001b[32m    484\u001b[39m     path_or_buf,\n\u001b[32m   (...)\u001b[39m\u001b[32m    490\u001b[39m     **kwargs,\n\u001b[32m    491\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/quantum-clinical-trial-optimization/lib/python3.11/site-packages/pandas/io/parquet.py:64\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m engine_class \u001b[38;5;129;01min\u001b[39;00m engine_classes:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     66\u001b[39m         error_msgs += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m - \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(err)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/quantum-clinical-trial-optimization/lib/python3.11/site-packages/pandas/io/parquet.py:170\u001b[39m, in \u001b[36mPyArrowImpl.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# import utils to register the pyarrow extension types\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension_types\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[38;5;28mself\u001b[39m.api = pyarrow\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/quantum-clinical-trial-optimization/lib/python3.11/site-packages/pandas/core/arrays/arrow/extension_types.py:174\u001b[39m\n\u001b[32m    167\u001b[39m     pyarrow.register_extension_type(\n\u001b[32m    168\u001b[39m         ForbiddenExtensionType(pyarrow.null(), \u001b[33m\"\u001b[39m\u001b[33marrow.py_extension_type\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    169\u001b[39m     )\n\u001b[32m    171\u001b[39m     pyarrow._hotfix_installed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[43mpatch_pyarrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/quantum-clinical-trial-optimization/lib/python3.11/site-packages/pandas/core/arrays/arrow/extension_types.py:166\u001b[39m, in \u001b[36mpatch_pyarrow\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    157\u001b[39m         pickletools.dis(serialized, out)\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    159\u001b[39m             _ERROR_MSG.format(\n\u001b[32m    160\u001b[39m                 storage_type=storage_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    163\u001b[39m             )\n\u001b[32m    164\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[43mpyarrow\u001b[49m\u001b[43m.\u001b[49m\u001b[43munregister_extension_type\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marrow.py_extension_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m pyarrow.register_extension_type(\n\u001b[32m    168\u001b[39m     ForbiddenExtensionType(pyarrow.null(), \u001b[33m\"\u001b[39m\u001b[33marrow.py_extension_type\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    169\u001b[39m )\n\u001b[32m    171\u001b[39m pyarrow._hotfix_installed = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/quantum-clinical-trial-optimization/lib/python3.11/site-packages/pyarrow/types.pxi:2280\u001b[39m, in \u001b[36mpyarrow.lib.unregister_extension_type\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/quantum-clinical-trial-optimization/lib/python3.11/site-packages/pyarrow/error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowKeyError\u001b[39m: No type extension with name arrow.py_extension_type found"
     ]
    }
   ],
   "source": [
    "# === Cell 7d: Persist clinical trials metadata as Parquet ===\n",
    "#\n",
    "# Purpose:\n",
    "#   - Save the same `all_records` DataFrame to a Parquet file for efficient\n",
    "#     downstream analytics (smaller, faster reads than CSV).\n",
    "#\n",
    "# Assumes:\n",
    "#   - `all_records` is still in memory from Cell 7.\n",
    "#   - `pyarrow` is installed successfully from Cell 7c.\n",
    "#   - `OUTPUT_DIR` exists (created in Cell 7b).\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "OUTPUT_DIR = Path(\"data/interim\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "metadata_path = OUTPUT_DIR / \"clinical_trials_metadata.parquet\"\n",
    "\n",
    "# Write the DataFrame to Parquet using pyarrow (default engine once installed)\n",
    "all_records.to_parquet(metadata_path, index=False)\n",
    "\n",
    "log(f\"[Cell 7d] Wrote Parquet metadata table to {metadata_path} with shape {all_records.shape}\")\n",
    "all_records.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18de7106-2182-462d-9f04-02d1cbc1e440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cell 7d] Wrote Parquet metadata table to data/interim/clinical_trials_metadata.parquet with shape (557292, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct_id</th>\n",
       "      <th>brief_title</th>\n",
       "      <th>official_title</th>\n",
       "      <th>overall_status</th>\n",
       "      <th>phase</th>\n",
       "      <th>conditions</th>\n",
       "      <th>interventions</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>location_countries</th>\n",
       "      <th>lead_sponsor</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>folder</th>\n",
       "      <th>s3_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT00000102</td>\n",
       "      <td>Congenital Adrenal Hyperplasia: Calcium Channe...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Phase 1/Phase 2</td>\n",
       "      <td>[Congenital Adrenal Hyperplasia]</td>\n",
       "      <td>[Nifedipine]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>4217</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT00000104</td>\n",
       "      <td>Does Lead Burden Alter Neuropsychological Deve...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>[Lead Poisoning]</td>\n",
       "      <td>[ERP measures of attention and memory]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>4357</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT00000105</td>\n",
       "      <td>Vaccination With Tetanus and KLH to Assess Imm...</td>\n",
       "      <td>Vaccination With Tetanus Toxoid and Keyhole Li...</td>\n",
       "      <td>Terminated</td>\n",
       "      <td>None</td>\n",
       "      <td>[Cancer]</td>\n",
       "      <td>[Intracel KLH Vaccine, Biosyn KLH, Montanide I...</td>\n",
       "      <td>112</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>Masonic Cancer Center, University of Minnesota</td>\n",
       "      <td>11623</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT00000106</td>\n",
       "      <td>41.8 Degree Centigrade Whole Body Hyperthermia...</td>\n",
       "      <td>None</td>\n",
       "      <td>Unknown status</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[Rheumatic Diseases]</td>\n",
       "      <td>[Whole body hyperthermia unit]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>5572</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT00000107</td>\n",
       "      <td>Body Water Content in Cyanotic Congenital Hear...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>[Heart Defects, Congenital]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>3312</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nct_id                                        brief_title  \\\n",
       "0  NCT00000102  Congenital Adrenal Hyperplasia: Calcium Channe...   \n",
       "1  NCT00000104  Does Lead Burden Alter Neuropsychological Deve...   \n",
       "2  NCT00000105  Vaccination With Tetanus and KLH to Assess Imm...   \n",
       "3  NCT00000106  41.8 Degree Centigrade Whole Body Hyperthermia...   \n",
       "4  NCT00000107  Body Water Content in Cyanotic Congenital Hear...   \n",
       "\n",
       "                                      official_title  overall_status  \\\n",
       "0                                               None       Completed   \n",
       "1                                               None       Completed   \n",
       "2  Vaccination With Tetanus Toxoid and Keyhole Li...      Terminated   \n",
       "3                                               None  Unknown status   \n",
       "4                                               None       Completed   \n",
       "\n",
       "             phase                        conditions  \\\n",
       "0  Phase 1/Phase 2  [Congenital Adrenal Hyperplasia]   \n",
       "1             None                  [Lead Poisoning]   \n",
       "2             None                          [Cancer]   \n",
       "3              N/A              [Rheumatic Diseases]   \n",
       "4             None       [Heart Defects, Congenital]   \n",
       "\n",
       "                                       interventions enrollment  \\\n",
       "0                                       [Nifedipine]       None   \n",
       "1             [ERP measures of attention and memory]       None   \n",
       "2  [Intracel KLH Vaccine, Biosyn KLH, Montanide I...        112   \n",
       "3                     [Whole body hyperthermia unit]       None   \n",
       "4                                                 []       None   \n",
       "\n",
       "  location_countries                                    lead_sponsor  \\\n",
       "0    [United States]   National Center for Research Resources (NCRR)   \n",
       "1    [United States]   National Center for Research Resources (NCRR)   \n",
       "2    [United States]  Masonic Cancer Center, University of Minnesota   \n",
       "3    [United States]   National Center for Research Resources (NCRR)   \n",
       "4    [United States]   National Center for Research Resources (NCRR)   \n",
       "\n",
       "   size_bytes             last_modified       folder  \\\n",
       "0        4217 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "1        4357 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "2       11623 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "3        5572 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "4        3312 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "\n",
       "                                              s3_key  \n",
       "0  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "1  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "2  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "3  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "4  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Cell 7d: Persist clinical trials metadata as Parquet using pyarrow directly ===\n",
    "#\n",
    "# Purpose:\n",
    "#   - Avoid pandas' parquet engine (which is throwing ArrowKeyError with pyarrow).\n",
    "#   - Use pyarrow directly to write the Parquet file from the in-memory DataFrame.\n",
    "#\n",
    "# Assumes:\n",
    "#   - `all_records` is defined and populated from the successful extraction.\n",
    "#   - `pyarrow` is already installed (via your earlier %pip install pyarrow).\n",
    "#   - CSV backup already exists from Cell 7b.\n",
    "\n",
    "from pathlib import Path\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Ensure output directory exists\n",
    "OUTPUT_DIR = Path(\"data/interim\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "metadata_path = OUTPUT_DIR / \"clinical_trials_metadata.parquet\"\n",
    "\n",
    "# Convert pandas DataFrame -> pyarrow Table\n",
    "# preserve_index=False so we do not store the DataFrame index as a column\n",
    "table = pa.Table.from_pandas(all_records, preserve_index=False)\n",
    "\n",
    "# Write the pyarrow Table directly to Parquet\n",
    "pq.write_table(table, metadata_path)\n",
    "\n",
    "log(f\"[Cell 7d] Wrote Parquet metadata table to {metadata_path} with shape {all_records.shape}\")\n",
    "all_records.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e40c07-99fb-4680-862f-cd59de4f5ce7",
   "metadata": {},
   "source": [
    "### Cell 7d — Persist Clinical-Trials Metadata as Parquet Using PyArrow Directly\n",
    "\n",
    "This cell writes the full clinical-trials metadata table to disk in Parquet format using `pyarrow` directly, sidestepping pandas’ parquet integration, which can be fragile for certain version combinations. It first ensures that the `data/interim` directory exists, then converts the `all_records` DataFrame into a `pyarrow.Table` with `preserve_index=False` so the pandas index is not stored as an extra column. The resulting table is written to `clinical_trials_metadata.parquet` via `pq.write_table`. A log message confirms the output path and the shape of the dataset, and a `.head()` call provides a quick visual sanity check. Together with the CSV backup from Cell 7b, this Parquet artifact becomes the primary, columnar source of truth for downstream analysis and scenario-building notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46f7bfac-dbe5-47f9-918f-07840ec26e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cell 7e] Reloaded Parquet has shape (557292, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct_id</th>\n",
       "      <th>brief_title</th>\n",
       "      <th>official_title</th>\n",
       "      <th>overall_status</th>\n",
       "      <th>phase</th>\n",
       "      <th>conditions</th>\n",
       "      <th>interventions</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>location_countries</th>\n",
       "      <th>lead_sponsor</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>folder</th>\n",
       "      <th>s3_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT00000102</td>\n",
       "      <td>Congenital Adrenal Hyperplasia: Calcium Channe...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Phase 1/Phase 2</td>\n",
       "      <td>[Congenital Adrenal Hyperplasia]</td>\n",
       "      <td>[Nifedipine]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>4217</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT00000104</td>\n",
       "      <td>Does Lead Burden Alter Neuropsychological Deve...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>[Lead Poisoning]</td>\n",
       "      <td>[ERP measures of attention and memory]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>4357</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT00000105</td>\n",
       "      <td>Vaccination With Tetanus and KLH to Assess Imm...</td>\n",
       "      <td>Vaccination With Tetanus Toxoid and Keyhole Li...</td>\n",
       "      <td>Terminated</td>\n",
       "      <td>None</td>\n",
       "      <td>[Cancer]</td>\n",
       "      <td>[Intracel KLH Vaccine, Biosyn KLH, Montanide I...</td>\n",
       "      <td>112</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>Masonic Cancer Center, University of Minnesota</td>\n",
       "      <td>11623</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT00000106</td>\n",
       "      <td>41.8 Degree Centigrade Whole Body Hyperthermia...</td>\n",
       "      <td>None</td>\n",
       "      <td>Unknown status</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[Rheumatic Diseases]</td>\n",
       "      <td>[Whole body hyperthermia unit]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>5572</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT00000107</td>\n",
       "      <td>Body Water Content in Cyanotic Congenital Hear...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>[Heart Defects, Congenital]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>3312</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nct_id                                        brief_title  \\\n",
       "0  NCT00000102  Congenital Adrenal Hyperplasia: Calcium Channe...   \n",
       "1  NCT00000104  Does Lead Burden Alter Neuropsychological Deve...   \n",
       "2  NCT00000105  Vaccination With Tetanus and KLH to Assess Imm...   \n",
       "3  NCT00000106  41.8 Degree Centigrade Whole Body Hyperthermia...   \n",
       "4  NCT00000107  Body Water Content in Cyanotic Congenital Hear...   \n",
       "\n",
       "                                      official_title  overall_status  \\\n",
       "0                                               None       Completed   \n",
       "1                                               None       Completed   \n",
       "2  Vaccination With Tetanus Toxoid and Keyhole Li...      Terminated   \n",
       "3                                               None  Unknown status   \n",
       "4                                               None       Completed   \n",
       "\n",
       "             phase                        conditions  \\\n",
       "0  Phase 1/Phase 2  [Congenital Adrenal Hyperplasia]   \n",
       "1             None                  [Lead Poisoning]   \n",
       "2             None                          [Cancer]   \n",
       "3              N/A              [Rheumatic Diseases]   \n",
       "4             None       [Heart Defects, Congenital]   \n",
       "\n",
       "                                       interventions enrollment  \\\n",
       "0                                       [Nifedipine]       None   \n",
       "1             [ERP measures of attention and memory]       None   \n",
       "2  [Intracel KLH Vaccine, Biosyn KLH, Montanide I...        112   \n",
       "3                     [Whole body hyperthermia unit]       None   \n",
       "4                                                 []       None   \n",
       "\n",
       "  location_countries                                    lead_sponsor  \\\n",
       "0    [United States]   National Center for Research Resources (NCRR)   \n",
       "1    [United States]   National Center for Research Resources (NCRR)   \n",
       "2    [United States]  Masonic Cancer Center, University of Minnesota   \n",
       "3    [United States]   National Center for Research Resources (NCRR)   \n",
       "4    [United States]   National Center for Research Resources (NCRR)   \n",
       "\n",
       "   size_bytes             last_modified       folder  \\\n",
       "0        4217 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "1        4357 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "2       11623 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "3        5572 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "4        3312 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "\n",
       "                                              s3_key  \n",
       "0  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "1  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "2  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "3  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "4  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Cell 7e: Verify Parquet round-trip ===\n",
    "#\n",
    "# Purpose:\n",
    "#   - Sanity-check that the Parquet file we wrote can be read back without issues.\n",
    "#   - This is just a small read and head() for confidence.\n",
    "\n",
    "from pathlib import Path\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "metadata_path = Path(\"data/interim/clinical_trials_metadata.parquet\")\n",
    "\n",
    "# Read Parquet via pyarrow\n",
    "table = pq.read_table(metadata_path)\n",
    "df_verify = table.to_pandas()\n",
    "\n",
    "log(f\"[Cell 7e] Reloaded Parquet has shape {df_verify.shape}\")\n",
    "df_verify.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b789cc2-07e6-4c56-9bd9-517ce26c7b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cell 8a] trials_meta created from df_verify with shape (557292, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct_id</th>\n",
       "      <th>brief_title</th>\n",
       "      <th>official_title</th>\n",
       "      <th>overall_status</th>\n",
       "      <th>phase</th>\n",
       "      <th>conditions</th>\n",
       "      <th>interventions</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>location_countries</th>\n",
       "      <th>lead_sponsor</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>folder</th>\n",
       "      <th>s3_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT00000102</td>\n",
       "      <td>Congenital Adrenal Hyperplasia: Calcium Channe...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Phase 1/Phase 2</td>\n",
       "      <td>[Congenital Adrenal Hyperplasia]</td>\n",
       "      <td>[Nifedipine]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>4217</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT00000104</td>\n",
       "      <td>Does Lead Burden Alter Neuropsychological Deve...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>[Lead Poisoning]</td>\n",
       "      <td>[ERP measures of attention and memory]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>4357</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT00000105</td>\n",
       "      <td>Vaccination With Tetanus and KLH to Assess Imm...</td>\n",
       "      <td>Vaccination With Tetanus Toxoid and Keyhole Li...</td>\n",
       "      <td>Terminated</td>\n",
       "      <td>None</td>\n",
       "      <td>[Cancer]</td>\n",
       "      <td>[Intracel KLH Vaccine, Biosyn KLH, Montanide I...</td>\n",
       "      <td>112</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>Masonic Cancer Center, University of Minnesota</td>\n",
       "      <td>11623</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT00000106</td>\n",
       "      <td>41.8 Degree Centigrade Whole Body Hyperthermia...</td>\n",
       "      <td>None</td>\n",
       "      <td>Unknown status</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[Rheumatic Diseases]</td>\n",
       "      <td>[Whole body hyperthermia unit]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>5572</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT00000107</td>\n",
       "      <td>Body Water Content in Cyanotic Congenital Hear...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>[Heart Defects, Congenital]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>3312</td>\n",
       "      <td>2025-11-14 10:58:29+00:00</td>\n",
       "      <td>NCT0000xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0000xxxx/NCT000001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nct_id                                        brief_title  \\\n",
       "0  NCT00000102  Congenital Adrenal Hyperplasia: Calcium Channe...   \n",
       "1  NCT00000104  Does Lead Burden Alter Neuropsychological Deve...   \n",
       "2  NCT00000105  Vaccination With Tetanus and KLH to Assess Imm...   \n",
       "3  NCT00000106  41.8 Degree Centigrade Whole Body Hyperthermia...   \n",
       "4  NCT00000107  Body Water Content in Cyanotic Congenital Hear...   \n",
       "\n",
       "                                      official_title  overall_status  \\\n",
       "0                                               None       Completed   \n",
       "1                                               None       Completed   \n",
       "2  Vaccination With Tetanus Toxoid and Keyhole Li...      Terminated   \n",
       "3                                               None  Unknown status   \n",
       "4                                               None       Completed   \n",
       "\n",
       "             phase                        conditions  \\\n",
       "0  Phase 1/Phase 2  [Congenital Adrenal Hyperplasia]   \n",
       "1             None                  [Lead Poisoning]   \n",
       "2             None                          [Cancer]   \n",
       "3              N/A              [Rheumatic Diseases]   \n",
       "4             None       [Heart Defects, Congenital]   \n",
       "\n",
       "                                       interventions enrollment  \\\n",
       "0                                       [Nifedipine]       None   \n",
       "1             [ERP measures of attention and memory]       None   \n",
       "2  [Intracel KLH Vaccine, Biosyn KLH, Montanide I...        112   \n",
       "3                     [Whole body hyperthermia unit]       None   \n",
       "4                                                 []       None   \n",
       "\n",
       "  location_countries                                    lead_sponsor  \\\n",
       "0    [United States]   National Center for Research Resources (NCRR)   \n",
       "1    [United States]   National Center for Research Resources (NCRR)   \n",
       "2    [United States]  Masonic Cancer Center, University of Minnesota   \n",
       "3    [United States]   National Center for Research Resources (NCRR)   \n",
       "4    [United States]   National Center for Research Resources (NCRR)   \n",
       "\n",
       "   size_bytes             last_modified       folder  \\\n",
       "0        4217 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "1        4357 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "2       11623 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "3        5572 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "4        3312 2025-11-14 10:58:29+00:00  NCT0000xxxx   \n",
       "\n",
       "                                              s3_key  \n",
       "0  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "1  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "2  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "3  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  \n",
       "4  clinical-trials-data/raw/NCT0000xxxx/NCT000001...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Cell 8a: Canonical in-memory metadata DataFrame ===\n",
    "#\n",
    "# Purpose:\n",
    "#   - Establish a single, clearly named DataFrame (`trials_meta`) that\n",
    "#     downstream notebooks will expect.\n",
    "#   - Option 1: If `df_verify` exists from Cell 7e, base it on that.\n",
    "#   - Option 2: If you're running this notebook fresh, load from Parquet.\n",
    "\n",
    "from pathlib import Path\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "metadata_path = Path(\"data/interim/clinical_trials_metadata.parquet\")\n",
    "\n",
    "if \"df_verify\" in globals():\n",
    "    # Reuse the DataFrame we just round-tripped from Parquet\n",
    "    trials_meta = df_verify.copy()\n",
    "    log(f\"[Cell 8a] trials_meta created from df_verify with shape {trials_meta.shape}\")\n",
    "else:\n",
    "    # Fresh load from Parquet if 7e wasn't run in this session\n",
    "    table = pq.read_table(metadata_path)\n",
    "    trials_meta = table.to_pandas()\n",
    "    log(f\"[Cell 8a] trials_meta loaded from {metadata_path} with shape {trials_meta.shape}\")\n",
    "\n",
    "trials_meta.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d111a765-e6a4-408e-af6d-09d47649448d",
   "metadata": {},
   "source": [
    "### Cell 8a — Define `trials_meta` as the Canonical Metadata Table\n",
    "\n",
    "This cell establishes `trials_meta` as the canonical in-memory DataFrame for all subsequent analysis in the notebook. If the Parquet round-trip check in Cell 7e has already been run, the cell simply copies `df_verify` into `trials_meta`, reusing the DataFrame that was just read back from `clinical_trials_metadata.parquet`. If not, it falls back to reading the Parquet file directly from `data/interim/clinical_trials_metadata.parquet` and converting it to a pandas DataFrame. In both cases, the cell logs the final shape and displays a small preview of `trials_meta`. Standardizing on this single, clearly named DataFrame makes later cells simpler and ensures that downstream notebooks can expect a consistent schema and naming convention when they load the clinical-trials metadata from disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5b4919a-1e7d-4222-9d84-43feec68b50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cell 8b] Basic info for trials_meta:\n",
      "Shape: (557292, 14)\n",
      "Columns: ['nct_id', 'brief_title', 'official_title', 'overall_status', 'phase', 'conditions', 'interventions', 'enrollment', 'location_countries', 'lead_sponsor', 'size_bytes', 'last_modified', 'folder', 's3_key']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nct_id</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brief_title</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>official_title</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_status</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phase</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conditions</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interventions</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enrollment</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location_countries</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_sponsor</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_bytes</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_modified</th>\n",
       "      <td>datetime64[ns, UTC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>folder</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3_key</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  dtype\n",
       "nct_id                           object\n",
       "brief_title                      object\n",
       "official_title                   object\n",
       "overall_status                   object\n",
       "phase                            object\n",
       "conditions                       object\n",
       "interventions                    object\n",
       "enrollment                       object\n",
       "location_countries               object\n",
       "lead_sponsor                     object\n",
       "size_bytes                        int64\n",
       "last_modified       datetime64[ns, UTC]\n",
       "folder                           object\n",
       "s3_key                           object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>phase</th>\n",
       "      <td>0.236404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>official_title</th>\n",
       "      <td>0.017921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enrollment</th>\n",
       "      <td>0.012652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nct_id</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brief_title</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_status</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conditions</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interventions</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location_countries</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_sponsor</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_bytes</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_modified</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>folder</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3_key</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    missing_fraction\n",
       "phase                       0.236404\n",
       "official_title              0.017921\n",
       "enrollment                  0.012652\n",
       "nct_id                      0.000000\n",
       "brief_title                 0.000000\n",
       "overall_status              0.000000\n",
       "conditions                  0.000000\n",
       "interventions               0.000000\n",
       "location_countries          0.000000\n",
       "lead_sponsor                0.000000\n",
       "size_bytes                  0.000000\n",
       "last_modified               0.000000\n",
       "folder                      0.000000\n",
       "s3_key                      0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cell 8b] Completed structural + missingness checks.\n"
     ]
    }
   ],
   "source": [
    "# === Cell 8b: Structural + missingness sanity checks ===\n",
    "#\n",
    "# Purpose:\n",
    "#   - Confirm basic properties of the metadata table:\n",
    "#       * Row/column counts\n",
    "#       * Column dtypes\n",
    "#       * Simple missingness overview\n",
    "#   - This helps catch any obvious ingestion anomalies before we build\n",
    "#     optimization scenarios on top of this data.\n",
    "\n",
    "log(\"[Cell 8b] Basic info for trials_meta:\")\n",
    "\n",
    "# Shape and columns\n",
    "log(f\"Shape: {trials_meta.shape}\")\n",
    "log(f\"Columns: {list(trials_meta.columns)}\")\n",
    "\n",
    "# Quick dtypes summary\n",
    "dtypes_summary = trials_meta.dtypes.to_frame(name=\"dtype\")\n",
    "display(dtypes_summary)\n",
    "\n",
    "# Simple missingness summary (fraction of nulls per column)\n",
    "missing_frac = trials_meta.isna().mean().sort_values(ascending=False)\n",
    "missing_summary = missing_frac.to_frame(name=\"missing_fraction\")\n",
    "display(missing_summary)\n",
    "\n",
    "log(\"[Cell 8b] Completed structural + missingness checks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7a14e7d-e013-4f9a-9a3e-d98944f9fa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cell 8c] nct_id: total rows=557,292, unique=557,292\n",
      "[Cell 8c] Top overall_status values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "overall_status\n",
       "Completed                    305099\n",
       "Unknown status                83373\n",
       "Recruiting                    65912\n",
       "Terminated                    32324\n",
       "Not yet recruiting            25016\n",
       "Active, not recruiting        21338\n",
       "Withdrawn                     15762\n",
       "Enrolling by invitation        4824\n",
       "Suspended                      1679\n",
       "Withheld                        947\n",
       "No longer available             503\n",
       "Available                       254\n",
       "Approved for marketing          233\n",
       "Temporarily not available        28\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cell 8c] Top phase values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "phase\n",
       "N/A                213089\n",
       "None               131746\n",
       "Phase 2             62166\n",
       "Phase 1             46196\n",
       "Phase 3             40582\n",
       "Phase 4             34286\n",
       "Phase 1/Phase 2     16062\n",
       "Phase 2/Phase 3      7260\n",
       "Early Phase 1        5905\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cell 8c] Top lead_sponsor values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lead_sponsor\n",
       "Assiut University                                                4348\n",
       "Cairo University                                                 4125\n",
       "GlaxoSmithKline                                                  3569\n",
       "National Cancer Institute (NCI)                                  3513\n",
       "AstraZeneca                                                      3347\n",
       "Assistance Publique - Hôpitaux de Paris                          3329\n",
       "Pfizer                                                           3211\n",
       "Mayo Clinic                                                      3110\n",
       "M.D. Anderson Cancer Center                                      2925\n",
       "Novartis Pharmaceuticals                                         2562\n",
       "Massachusetts General Hospital                                   2464\n",
       "National Taiwan University Hospital                              2454\n",
       "National Institute of Allergy and Infectious Diseases (NIAID)    2419\n",
       "Boehringer Ingelheim                                             2247\n",
       "Merck Sharp & Dohme LLC                                          2079\n",
       "Stanford University                                              2054\n",
       "University of California, San Francisco                          2053\n",
       "Hoffmann-La Roche                                                2043\n",
       "Eli Lilly and Company                                            2000\n",
       "Duke University                                                  1980\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cell 8c] Completed domain sanity checks.\n"
     ]
    }
   ],
   "source": [
    "# === Cell 8c: Domain sanity checks on key fields ===\n",
    "#\n",
    "# Purpose:\n",
    "#   - Confirm 1 row per trial (`nct_id` uniqueness).\n",
    "#   - Inspect distributions of high-level fields used later in scenarios\n",
    "#     (e.g., phase, overall_status, lead_sponsor).\n",
    "#\n",
    "# Assumes:\n",
    "#   - Column names include at least: 'nct_id', 'overall_status', 'phase', 'lead_sponsor'.\n",
    "\n",
    "# 1) Check uniqueness of nct_id\n",
    "if \"nct_id\" in trials_meta.columns:\n",
    "    total_nct = trials_meta[\"nct_id\"].shape[0]\n",
    "    unique_nct = trials_meta[\"nct_id\"].nunique(dropna=True)\n",
    "    log(f\"[Cell 8c] nct_id: total rows={total_nct:,}, unique={unique_nct:,}\")\n",
    "\n",
    "    if total_nct != unique_nct:\n",
    "        log(\"[Cell 8c] WARNING: nct_id is not unique; multiple rows per trial detected.\")\n",
    "else:\n",
    "    log(\"[Cell 8c] WARNING: 'nct_id' column not found in trials_meta.\")\n",
    "\n",
    "# 2) Distribution of overall_status\n",
    "if \"overall_status\" in trials_meta.columns:\n",
    "    log(\"[Cell 8c] Top overall_status values:\")\n",
    "    display(trials_meta[\"overall_status\"].value_counts(dropna=False).head(20))\n",
    "else:\n",
    "    log(\"[Cell 8c] WARNING: 'overall_status' column not found in trials_meta.\")\n",
    "\n",
    "# 3) Distribution of phase\n",
    "if \"phase\" in trials_meta.columns:\n",
    "    log(\"[Cell 8c] Top phase values:\")\n",
    "    display(trials_meta[\"phase\"].value_counts(dropna=False).head(20))\n",
    "else:\n",
    "    log(\"[Cell 8c] WARNING: 'phase' column not found in trials_meta.\")\n",
    "\n",
    "# 4) Top lead sponsors (helpful for later scenario design)\n",
    "if \"lead_sponsor\" in trials_meta.columns:\n",
    "    log(\"[Cell 8c] Top lead_sponsor values:\")\n",
    "    display(trials_meta[\"lead_sponsor\"].value_counts(dropna=False).head(20))\n",
    "else:\n",
    "    log(\"[Cell 8c] WARNING: 'lead_sponsor' column not found in trials_meta.\")\n",
    "\n",
    "log(\"[Cell 8c] Completed domain sanity checks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec4aeb49-7234-48e1-8f9b-e8d614ab443a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cell 8d] Wrote overall_status summary to data/summary/clinical_trials_overall_status_counts.csv\n",
      "[Cell 8d] Wrote phase summary to data/summary/clinical_trials_phase_counts.csv\n",
      "[Cell 8d] Wrote top-50 lead_sponsor summary to data/summary/clinical_trials_lead_sponsor_top50.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                     count\n",
       " overall_status            \n",
       " Completed           305099\n",
       " Unknown status       83373\n",
       " Recruiting           65912\n",
       " Terminated           32324\n",
       " Not yet recruiting   25016,\n",
       "           count\n",
       " phase          \n",
       " N/A      213089\n",
       " None     131746\n",
       " Phase 2   62166\n",
       " Phase 1   46196\n",
       " Phase 3   40582,\n",
       "                                  count\n",
       " lead_sponsor                          \n",
       " Assiut University                 4348\n",
       " Cairo University                  4125\n",
       " GlaxoSmithKline                   3569\n",
       " National Cancer Institute (NCI)   3513\n",
       " AstraZeneca                       3347)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Cell 8d: Persist summary tables for quick reference ===\n",
    "#\n",
    "# Purpose:\n",
    "#   - Save lightweight summary tables derived from `trials_meta` so that\n",
    "#     other notebooks (or slide decks) can reuse them without recomputing.\n",
    "#   - Examples:\n",
    "#       * overall_status counts\n",
    "#       * phase counts\n",
    "#       * top lead sponsors\n",
    "#\n",
    "# Output:\n",
    "#   - data/summary/clinical_trials_overall_status_counts.csv\n",
    "#   - data/summary/clinical_trials_phase_counts.csv\n",
    "#   - data/summary/clinical_trials_lead_sponsor_top50.csv\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "SUMMARY_DIR = Path(\"data/summary\")\n",
    "SUMMARY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) overall_status counts\n",
    "status_counts = (\n",
    "    trials_meta[\"overall_status\"]\n",
    "    .value_counts(dropna=False)\n",
    "    .rename_axis(\"overall_status\")\n",
    "    .to_frame(name=\"count\")\n",
    ")\n",
    "status_path = SUMMARY_DIR / \"clinical_trials_overall_status_counts.csv\"\n",
    "status_counts.to_csv(status_path)\n",
    "log(f\"[Cell 8d] Wrote overall_status summary to {status_path}\")\n",
    "\n",
    "# 2) phase counts\n",
    "phase_counts = (\n",
    "    trials_meta[\"phase\"]\n",
    "    .value_counts(dropna=False)\n",
    "    .rename_axis(\"phase\")\n",
    "    .to_frame(name=\"count\")\n",
    ")\n",
    "phase_path = SUMMARY_DIR / \"clinical_trials_phase_counts.csv\"\n",
    "phase_counts.to_csv(phase_path)\n",
    "log(f\"[Cell 8d] Wrote phase summary to {phase_path}\")\n",
    "\n",
    "# 3) top lead sponsors (limit to top 50 for readability)\n",
    "sponsor_counts = (\n",
    "    trials_meta[\"lead_sponsor\"]\n",
    "    .value_counts(dropna=False)\n",
    "    .head(50)\n",
    "    .rename_axis(\"lead_sponsor\")\n",
    "    .to_frame(name=\"count\")\n",
    ")\n",
    "sponsor_path = SUMMARY_DIR / \"clinical_trials_lead_sponsor_top50.csv\"\n",
    "sponsor_counts.to_csv(sponsor_path)\n",
    "log(f\"[Cell 8d] Wrote top-50 lead_sponsor summary to {sponsor_path}\")\n",
    "\n",
    "status_counts.head(), phase_counts.head(), sponsor_counts.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff531cdd-f137-40d4-8b1e-af754101b351",
   "metadata": {},
   "source": [
    "### Cell 8d — Persist High-Level Summary Tables for Reuse\n",
    "\n",
    "This cell derives and saves lightweight summary tables that capture the overall shape of the clinical-trial portfolio without needing to reload the full 557k-row dataset. Using `trials_meta`, it computes frequency tables for `overall_status`, `phase`, and the top 50 `lead_sponsor` values, then writes each result to a CSV file under `data/summary/`. These summaries make it easy to reuse portfolio-level statistics in other notebooks, reports, or slide decks without recomputing them from scratch. The log messages record the output file paths, and the displayed heads provide a quick visual check that the aggregated counts look reasonable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03471e3e-d276-4129-8fc8-e0a7dc529e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cell 8e] Drew a reproducible sample of 10,000 rows from 557,292 total.\n",
      "[Cell 8e] Wrote sample CSV to data/interim/clinical_trials_metadata_sample.csv.gz\n",
      "[Cell 8e] Wrote sample Parquet to data/interim/clinical_trials_metadata_sample.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct_id</th>\n",
       "      <th>brief_title</th>\n",
       "      <th>official_title</th>\n",
       "      <th>overall_status</th>\n",
       "      <th>phase</th>\n",
       "      <th>conditions</th>\n",
       "      <th>interventions</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>location_countries</th>\n",
       "      <th>lead_sponsor</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>folder</th>\n",
       "      <th>s3_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218080</th>\n",
       "      <td>NCT02811120</td>\n",
       "      <td>PRIME Follow up - Quadri Meningo Vacinees</td>\n",
       "      <td>An Observational Follow up Study of a Phase II...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>[Meningococcal Disease]</td>\n",
       "      <td>[venepuncture only]</td>\n",
       "      <td>57</td>\n",
       "      <td>[]</td>\n",
       "      <td>Public Health England</td>\n",
       "      <td>10465</td>\n",
       "      <td>2025-11-17 14:27:07+00:00</td>\n",
       "      <td>NCT0281xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0281xxxx/NCT028111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274981</th>\n",
       "      <td>NCT03552926</td>\n",
       "      <td>Constitution of a Clinico-radiological Databas...</td>\n",
       "      <td>Constitution of a Clinico-radiological Databas...</td>\n",
       "      <td>Recruiting</td>\n",
       "      <td>None</td>\n",
       "      <td>[Lacunar Strokes]</td>\n",
       "      <td>[]</td>\n",
       "      <td>500</td>\n",
       "      <td>[France]</td>\n",
       "      <td>Assistance Publique - Hôpitaux de Paris</td>\n",
       "      <td>9624</td>\n",
       "      <td>2025-11-17 13:24:50+00:00</td>\n",
       "      <td>NCT0355xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0355xxxx/NCT035529...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284107</th>\n",
       "      <td>NCT03671863</td>\n",
       "      <td>Children Born With Club Feet</td>\n",
       "      <td>Children Born With Club Feet: Ultrasound Diagn...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>[Clubfoot]</td>\n",
       "      <td>[Invasive analysis (caryotype, CGH array), Pre...</td>\n",
       "      <td>219</td>\n",
       "      <td>[France]</td>\n",
       "      <td>University Hospital, Montpellier</td>\n",
       "      <td>8300</td>\n",
       "      <td>2025-11-18 08:37:55+00:00</td>\n",
       "      <td>NCT0367xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0367xxxx/NCT036718...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508776</th>\n",
       "      <td>NCT06597084</td>\n",
       "      <td>Anti-epileptogenic Effects of Eslicarbazepine ...</td>\n",
       "      <td>Prevention of Epilepsy in Stroke Patients at H...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Phase 2</td>\n",
       "      <td>[Post Stroke Epilepsy]</td>\n",
       "      <td>[ESL 800 mg, Placebo]</td>\n",
       "      <td>129</td>\n",
       "      <td>[Austria, France, Germany, Israel, Italy, Port...</td>\n",
       "      <td>Bial - Portela C S.A.</td>\n",
       "      <td>233193</td>\n",
       "      <td>2025-11-14 15:58:13+00:00</td>\n",
       "      <td>NCT0659xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0659xxxx/NCT065970...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285400</th>\n",
       "      <td>NCT03688685</td>\n",
       "      <td>A Clinical Study to Evaluate CAD-1883 in Essen...</td>\n",
       "      <td>A Phase 2a Open-Label Study to Evaluate the Sa...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Phase 2</td>\n",
       "      <td>[Essential Tremor]</td>\n",
       "      <td>[CAD-1883]</td>\n",
       "      <td>25</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>Cadent Therapeutics</td>\n",
       "      <td>29053</td>\n",
       "      <td>2025-11-16 21:43:28+00:00</td>\n",
       "      <td>NCT0368xxxx</td>\n",
       "      <td>clinical-trials-data/raw/NCT0368xxxx/NCT036886...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             nct_id                                        brief_title  \\\n",
       "218080  NCT02811120          PRIME Follow up - Quadri Meningo Vacinees   \n",
       "274981  NCT03552926  Constitution of a Clinico-radiological Databas...   \n",
       "284107  NCT03671863                       Children Born With Club Feet   \n",
       "508776  NCT06597084  Anti-epileptogenic Effects of Eslicarbazepine ...   \n",
       "285400  NCT03688685  A Clinical Study to Evaluate CAD-1883 in Essen...   \n",
       "\n",
       "                                           official_title overall_status  \\\n",
       "218080  An Observational Follow up Study of a Phase II...      Completed   \n",
       "274981  Constitution of a Clinico-radiological Databas...     Recruiting   \n",
       "284107  Children Born With Club Feet: Ultrasound Diagn...      Completed   \n",
       "508776  Prevention of Epilepsy in Stroke Patients at H...      Completed   \n",
       "285400  A Phase 2a Open-Label Study to Evaluate the Sa...      Completed   \n",
       "\n",
       "          phase               conditions  \\\n",
       "218080     None  [Meningococcal Disease]   \n",
       "274981     None        [Lacunar Strokes]   \n",
       "284107     None               [Clubfoot]   \n",
       "508776  Phase 2   [Post Stroke Epilepsy]   \n",
       "285400  Phase 2       [Essential Tremor]   \n",
       "\n",
       "                                            interventions enrollment  \\\n",
       "218080                                [venepuncture only]         57   \n",
       "274981                                                 []        500   \n",
       "284107  [Invasive analysis (caryotype, CGH array), Pre...        219   \n",
       "508776                              [ESL 800 mg, Placebo]        129   \n",
       "285400                                         [CAD-1883]         25   \n",
       "\n",
       "                                       location_countries  \\\n",
       "218080                                                 []   \n",
       "274981                                           [France]   \n",
       "284107                                           [France]   \n",
       "508776  [Austria, France, Germany, Israel, Italy, Port...   \n",
       "285400                                    [United States]   \n",
       "\n",
       "                                   lead_sponsor  size_bytes  \\\n",
       "218080                    Public Health England       10465   \n",
       "274981  Assistance Publique - Hôpitaux de Paris        9624   \n",
       "284107         University Hospital, Montpellier        8300   \n",
       "508776                    Bial - Portela C S.A.      233193   \n",
       "285400                      Cadent Therapeutics       29053   \n",
       "\n",
       "                   last_modified       folder  \\\n",
       "218080 2025-11-17 14:27:07+00:00  NCT0281xxxx   \n",
       "274981 2025-11-17 13:24:50+00:00  NCT0355xxxx   \n",
       "284107 2025-11-18 08:37:55+00:00  NCT0367xxxx   \n",
       "508776 2025-11-14 15:58:13+00:00  NCT0659xxxx   \n",
       "285400 2025-11-16 21:43:28+00:00  NCT0368xxxx   \n",
       "\n",
       "                                                   s3_key  \n",
       "218080  clinical-trials-data/raw/NCT0281xxxx/NCT028111...  \n",
       "274981  clinical-trials-data/raw/NCT0355xxxx/NCT035529...  \n",
       "284107  clinical-trials-data/raw/NCT0367xxxx/NCT036718...  \n",
       "508776  clinical-trials-data/raw/NCT0659xxxx/NCT065970...  \n",
       "285400  clinical-trials-data/raw/NCT0368xxxx/NCT036886...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Cell 8e: Create a small sample subset for rapid experimentation ===\n",
    "#\n",
    "# Purpose:\n",
    "#   - Create a small, stable subset of trials (e.g., 10,000 rows) that we can\n",
    "#     use in downstream notebooks for quick iteration without always loading\n",
    "#     the full ~557k table.\n",
    "#\n",
    "# Notes:\n",
    "#   - We use .sample(..., random_state=42) for reproducibility.\n",
    "#   - We write both CSV (gzipped) and Parquet versions.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "SAMPLE_DIR = Path(\"data/interim\")\n",
    "SAMPLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sample_n = 10_000  # adjust as desired\n",
    "\n",
    "if len(trials_meta) <= sample_n:\n",
    "    trials_sample = trials_meta.copy()\n",
    "    log(f\"[Cell 8e] Dataset has {len(trials_meta):,} rows; using full table as 'sample'.\")\n",
    "else:\n",
    "    trials_sample = trials_meta.sample(n=sample_n, random_state=42)\n",
    "    log(f\"[Cell 8e] Drew a reproducible sample of {sample_n:,} rows from {len(trials_meta):,} total.\")\n",
    "\n",
    "# Write CSV.gz\n",
    "sample_csv_path = SAMPLE_DIR / \"clinical_trials_metadata_sample.csv.gz\"\n",
    "trials_sample.to_csv(sample_csv_path, index=False, compression=\"gzip\")\n",
    "log(f\"[Cell 8e] Wrote sample CSV to {sample_csv_path}\")\n",
    "\n",
    "# Write Parquet via pyarrow directly (bypassing pandas.to_parquet)\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "sample_parquet_path = SAMPLE_DIR / \"clinical_trials_metadata_sample.parquet\"\n",
    "sample_table = pa.Table.from_pandas(trials_sample, preserve_index=False)\n",
    "pq.write_table(sample_table, sample_parquet_path)\n",
    "log(f\"[Cell 8e] Wrote sample Parquet to {sample_parquet_path}\")\n",
    "\n",
    "trials_sample.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be152b07-8c13-4631-8c3f-654c86e3aff2",
   "metadata": {},
   "source": [
    "### Cell 8e — Create a Reproducible Sample Subset for Fast Iteration\n",
    "\n",
    "This cell builds a smaller, reproducible subset of `trials_meta` for rapid experimentation in downstream notebooks. If the full dataset has more than `sample_n` rows (default 10,000), it draws a random sample of that size using a fixed `random_state` so the same trials are selected every time. If the corpus is smaller than `sample_n`, it simply uses the entire table as the “sample.” The resulting `trials_sample` DataFrame is then written to disk in two formats: a gzipped CSV (`clinical_trials_metadata_sample.csv.gz`) for maximal interoperability, and a Parquet file (`clinical_trials_metadata_sample.parquet`) written via pyarrow for efficient, columnar access. Log messages record both output paths and the sample size. This sampled subset provides a lightweight playground for feature engineering, scenario design, and QUBO construction without incurring the overhead of repeatedly scanning all 557k trials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b4f164-5ce5-49b2-bacd-37a125552107",
   "metadata": {},
   "source": [
    "### Final Summary and Next Steps\n",
    "\n",
    "This notebook ingests the full ClinicalTrials.gov corpus from S3 and converts it into a clean, analysis-ready metadata table suitable for downstream optimization and quantum experiments.\n",
    "\n",
    "**What this notebook accomplished:**\n",
    "\n",
    "- Verified the AWS environment and S3 connectivity to the `quantum-clinical-optimization-us-west-2` bucket.\n",
    "- Built a comprehensive S3 index (`df_index`) of all ClinicalTrials.gov XML files, including NCT IDs, folder groups, file sizes, and last-modified timestamps.\n",
    "- Implemented robust, fault-tolerant XML parsing utilities and validated them on both a single trial and a random sample.\n",
    "- Performed high-throughput, parallel extraction of trial-level metadata for all ~557k trials into a unified `all_records` / `trials_meta` DataFrame.\n",
    "- Persisted the full metadata table to disk in multiple formats:\n",
    "  - Engine-agnostic backup: `data/interim/clinical_trials_metadata.csv.gz`\n",
    "  - Columnar primary artifact: `data/interim/clinical_trials_metadata.parquet`\n",
    "- Verified Parquet round-trip integrity and established `trials_meta` as the canonical in-memory table.\n",
    "- Ran structural and domain-level sanity checks (uniqueness of `nct_id`, distributions of `overall_status` and `phase`, and leading sponsors).\n",
    "- Exported lightweight summary tables and a reproducible 10k-row sample to support fast iteration in later notebooks.\n",
    "\n",
    "Together, these steps turn a large, heterogeneous XML corpus in S3 into a stable, well-understood foundation for analytics and optimization.\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps (Notebook 02 and Beyond)\n",
    "\n",
    "The next notebook will build on `clinical_trials_metadata.parquet` to move from **raw metadata** to **concrete optimization scenarios**:\n",
    "\n",
    "1. **Load and Filter Metadata**\n",
    "   - Read `clinical_trials_metadata.parquet` (or the 10k-row sample).\n",
    "   - Focus on one or more use cases, such as a specific:\n",
    "     - Therapeutic area (e.g., oncology, cardiology),\n",
    "     - Development phase (e.g., Phase 2 / 3),\n",
    "     - Sponsor or portfolio slice.\n",
    "\n",
    "2. **Feature Engineering for Scenario Design**\n",
    "   - Derive features needed for site/trial selection scenarios:\n",
    "     - Enrollment size and status,\n",
    "     - Number and diversity of locations,\n",
    "     - Sponsor and phase characteristics.\n",
    "   - Optionally join additional S3-backed datasets (e.g., site performance or cost data).\n",
    "\n",
    "3. **Define Optimization Scenarios**\n",
    "   - Formalize a small set of decision problems, such as:\n",
    "     - Selecting a subset of trials for a constrained portfolio.\n",
    "     - Selecting sites or regions for a given protocol under budget and capacity limits.\n",
    "   - Specify objectives (e.g., maximize expected enrollment speed or diversity) and hard/soft constraints.\n",
    "\n",
    "4. **Construct QUBO Instances**\n",
    "   - Encode each scenario as a binary decision vector (e.g., one variable per site or trial).\n",
    "   - Translate objectives and constraints into a QUBO/Ising formulation.\n",
    "   - Serialize each QUBO instance (e.g., JSON or NumPy-based format) and save it to S3 or `data/qubo_scenarios/`.\n",
    "\n",
    "5. **Prepare for Quantum and Classical Solvers (Notebook 03)**\n",
    "   - Define a small set of benchmark scenarios to send to:\n",
    "     - Classical optimizers (exact or heuristic) as baselines.\n",
    "     - AWS Braket QAOA workflows on SV1 or other backends.\n",
    "   - Record metrics for comparison (objective value, constraint violations, runtime, sampling profiles).\n",
    "\n",
    "At this point, Notebook 01 can be considered **complete**: it owns ingestion, indexing, and core metadata validation. Notebook 02 will focus on **scenario building and QUBO construction**, and Notebook 03 will handle **solver execution and comparative analysis**, including Braket-based quantum and quantum-inspired runs.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (quantum-clinical-trial-optimization)",
   "language": "python",
   "name": "quantum-clinical-trial-optimization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
